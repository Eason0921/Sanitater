{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eae6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90584b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义是否使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d48ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络结构\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(     #input_size=(1*28*28)\n",
    "            nn.Conv2d(1, 6, 5, 1, 2), #padding=2保证输入输出尺寸相同（28-5+2*2）/1+1=28\n",
    "            #in_channels,out_channels,kernel_size,stride,padding\n",
    "            nn.ReLU(),      #input_size=(6*28*28)\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),#output_size=(6*14*14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 5),#input_size=(6*14*14)(14-5+0*2)/1+1=10\n",
    "            nn.ReLU(),      #input_size=(16*10*10)\n",
    "            nn.MaxPool2d(2, 2)  #output_size=(16*5*5)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16 * 5 * 5, 120),#全连接层1#input_size=(16*5*5)\n",
    "            #nn.linear(in_features,out_features)代表形状\n",
    "            nn.ReLU()#output_szie=(120)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(120, 84),#input_size=(120)\n",
    "            nn.ReLU()#output_size=(84)\n",
    "        )\n",
    "        self.fc3 = nn.Linear(84, 10)#output: 10 possiblities\n",
    "         # 定义前向传播过程，输入为x\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = x.view(x.size()[0], -1)# nn.Linear()的输入输出都是维度为一的值，所以把多维度的tensor展平成一维\n",
    "       \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2926ef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--outf', default='./model/', help='folder to output images and model checkpoints') \n",
    "#模型保存路径\n",
    "parser.add_argument('--net', default='./model/net.pth', help=\"path to netG (to continue training)\")  \n",
    "#模型加载路径\n",
    "opt = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d1f2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "EPOCH = 10   #遍历数据集、权重更新迭代次数,数据集多样化越强epoch越大。\n",
    "#随着epoch 数量的增加， 权重更新迭代的次数增多， 曲线从最开始的不拟合状态， 进入优化拟合状态， 最终进入过拟合\n",
    "BATCH_SIZE = 64      #批处理尺寸(batch_size)，每个batch中（在实际训练时、 将所有数据分成多个batch ， 每次送入一部分数据）训练样本的数量\n",
    "LR = 0.001        #学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddc03641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据预处理方式\n",
    "#变换图像数据为tensor,形状为[channel,height,width]\n",
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118f951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练数据集\n",
    "trainset = tv.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,#读入数据为训练集\n",
    "    download=True,#根目录root没有数据集，自动下载\n",
    "    transform=transform #读入上一段的数据预处理方式\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8247733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练批处理数据\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    dataset=trainset,#加载数据的数据集\n",
    "    batch_size=BATCH_SIZE,#每个batch加载多少个样本\n",
    "    shuffle=True,#默认为false，设置为true会在每个epoch重新打乱数据（鲁棒性、防止过拟合）\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b1a136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义测试数据集\n",
    "testset = tv.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aece2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义测试批处理数据\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    dataset=testset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20aa27f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数loss function 和优化方式（采用SGD）\n",
    "net = LeNet().to(device)\n",
    "#损失函数\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数，通常用于多分类问题上\n",
    "#优化器 SGD/Momentun/RMSprop/Adam\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n",
    "#(params, lr=<required parameter>, momentum=0, dampening=0, weight_decay=0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f97dd8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 2.298\n",
      "[1, 200] loss: 2.288\n",
      "[1, 300] loss: 2.269\n",
      "[1, 400] loss: 2.232\n",
      "[1, 500] loss: 2.130\n",
      "[1, 600] loss: 1.705\n",
      "[1, 700] loss: 0.956\n",
      "[1, 800] loss: 0.696\n",
      "[1, 900] loss: 0.576\n",
      "第1个epoch的识别准确率为：85%\n",
      "[2, 100] loss: 0.450\n",
      "[2, 200] loss: 0.421\n",
      "[2, 300] loss: 0.387\n",
      "[2, 400] loss: 0.360\n",
      "[2, 500] loss: 0.323\n",
      "[2, 600] loss: 0.307\n",
      "[2, 700] loss: 0.301\n",
      "[2, 800] loss: 0.302\n",
      "[2, 900] loss: 0.248\n",
      "第2个epoch的识别准确率为：93%\n",
      "[3, 100] loss: 0.240\n",
      "[3, 200] loss: 0.233\n",
      "[3, 300] loss: 0.225\n",
      "[3, 400] loss: 0.208\n",
      "[3, 500] loss: 0.199\n",
      "[3, 600] loss: 0.210\n",
      "[3, 700] loss: 0.176\n",
      "[3, 800] loss: 0.189\n",
      "[3, 900] loss: 0.183\n",
      "第3个epoch的识别准确率为：94%\n",
      "[4, 100] loss: 0.171\n",
      "[4, 200] loss: 0.158\n",
      "[4, 300] loss: 0.152\n",
      "[4, 400] loss: 0.162\n",
      "[4, 500] loss: 0.147\n",
      "[4, 600] loss: 0.155\n",
      "[4, 700] loss: 0.137\n",
      "[4, 800] loss: 0.151\n",
      "[4, 900] loss: 0.129\n",
      "第4个epoch的识别准确率为：96%\n",
      "[5, 100] loss: 0.127\n",
      "[5, 200] loss: 0.137\n",
      "[5, 300] loss: 0.133\n",
      "[5, 400] loss: 0.131\n",
      "[5, 500] loss: 0.120\n",
      "[5, 600] loss: 0.115\n",
      "[5, 700] loss: 0.101\n",
      "[5, 800] loss: 0.108\n",
      "[5, 900] loss: 0.118\n",
      "第5个epoch的识别准确率为：96%\n",
      "[6, 100] loss: 0.104\n",
      "[6, 200] loss: 0.103\n",
      "[6, 300] loss: 0.107\n",
      "[6, 400] loss: 0.110\n",
      "[6, 500] loss: 0.101\n",
      "[6, 600] loss: 0.096\n",
      "[6, 700] loss: 0.099\n",
      "[6, 800] loss: 0.096\n",
      "[6, 900] loss: 0.087\n",
      "第6个epoch的识别准确率为：97%\n",
      "[7, 100] loss: 0.088\n",
      "[7, 200] loss: 0.098\n",
      "[7, 300] loss: 0.085\n",
      "[7, 400] loss: 0.093\n",
      "[7, 500] loss: 0.085\n",
      "[7, 600] loss: 0.089\n",
      "[7, 700] loss: 0.084\n",
      "[7, 800] loss: 0.089\n",
      "[7, 900] loss: 0.082\n",
      "第7个epoch的识别准确率为：97%\n",
      "[8, 100] loss: 0.083\n",
      "[8, 200] loss: 0.079\n",
      "[8, 300] loss: 0.074\n",
      "[8, 400] loss: 0.077\n",
      "[8, 500] loss: 0.077\n",
      "[8, 600] loss: 0.088\n",
      "[8, 700] loss: 0.087\n",
      "[8, 800] loss: 0.065\n",
      "[8, 900] loss: 0.079\n",
      "第8个epoch的识别准确率为：97%\n",
      "[9, 100] loss: 0.065\n",
      "[9, 200] loss: 0.075\n",
      "[9, 300] loss: 0.075\n",
      "[9, 400] loss: 0.072\n",
      "[9, 500] loss: 0.067\n",
      "[9, 600] loss: 0.070\n",
      "[9, 700] loss: 0.068\n",
      "[9, 800] loss: 0.076\n",
      "[9, 900] loss: 0.072\n",
      "第9个epoch的识别准确率为：97%\n",
      "[10, 100] loss: 0.062\n",
      "[10, 200] loss: 0.070\n",
      "[10, 300] loss: 0.063\n",
      "[10, 400] loss: 0.064\n",
      "[10, 500] loss: 0.074\n",
      "[10, 600] loss: 0.065\n",
      "[10, 700] loss: 0.067\n",
      "[10, 800] loss: 0.056\n",
      "[10, 900] loss: 0.066\n",
      "第10个epoch的识别准确率为：97%\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        sum_loss = 0.0\n",
    "        # 数据读取\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 以前梯度清零\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()#反向传播，计算当前梯度\n",
    "            optimizer.step()#根据梯度更新网络参数\n",
    "\n",
    "            # 每训练100个batch打印一次平均loss\n",
    "            sum_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %d] loss: %.03f'#loss保留三位小数\n",
    "                      % (epoch + 1, i + 1, sum_loss / 100))\n",
    "                sum_loss = 0.0\n",
    "        # 每跑完一次epoch测试一下准确\n",
    "        #所有计算得出的tensor的requires_grad都自动设置为False，反向传播不会自动求导\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                # 取得分最高的那个类\n",
    "                _, predicted = torch.max(outputs.data, dim=1)#dim=1：输出所在行的最大值\n",
    "                #torch.max返回两个值，第一个是具体的value（对应_),第二个是value对应的index（对应predicted）\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            print('第%d个epoch的识别准确率为：%d%%' % (epoch + 1, (100 * correct / total)))\n",
    "    torch.save(net.state_dict(), '%s/net_%03d.pth' % (opt.outf, epoch + 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
